---
title: "Sample Report - Data Science Capstone"
author: "Ibrahim Khan"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: STA 6257 - Advanced Statistical Modeling
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

## Week 1 Research Paper Summary
  - Summary Paper 1: [@nadkarni2011natural]
    - The paper "Natural Language Processing: An Introduction" by Prakash M Nadkarni, Lucila Ohno-Machado, and Wendy W Chapman provides an extensive tutorial on natural language processing (NLP) aimed at medical informatics generalists. It traces the evolution of NLP from its origins in the 1950s to the present, highlighting the convergence of NLP with information retrieval and the rise of statistical methods in the 1980s. The tutorial covers the historical challenges of rule-based approaches and the transition to statistical NLP, which utilizes large annotated corpora and machine learning algorithms to improve parsing and interpretation. Various NLP sub-problems are discussed, including sentence boundary detection, tokenization, part-of-speech tagging, and named entity recognition, with a focus on their application to clinical text. The article also explores higher-level tasks such as relationship extraction and information extraction, emphasizing the complementary nature of rule-based and statistical approaches in modern NLP systems.
  - Summary Paper 2: [@webster1992tokenization]
    - The paper "Tokenization as the Initial Phase in NLP" by Jonathan J. Webster and Chunyu Kit explores the critical role of tokenization in natural language processing (NLP). Tokenization involves splitting text into individual tokens, which are essential for various NLP tasks such as part-of-speech tagging and parsing. The process is challenged by complexities in biomedical text, where tokens often contain characters used as token boundaries, such as hyphens and slashes. The paper highlights the importance of accurately identifying sentence boundaries, handling abbreviations and titles, and segmenting text into meaningful units. The authors discuss different tokenization techniques and their impact on downstream NLP tasks, emphasizing the need for robust methods to handle the unique characteristics of clinical narratives. Although tokenization may seem straightforward, its accuracy significantly influences the effectiveness of subsequent NLP applications in healthcare, such as information extraction and electronic health record analysis.

## Week 2 Research Paper Summary
  - Summary Paper 1: [@9036670]
    - The paper "Sentiment Analysis with NLP on Twitter Data" by Md. Rakibul Hasan, Maisha Maliha, and M. Arifuzzaman explores how businesses can leverage Twitter data to gauge public opinion on their products. The authors developed a natural language processing (NLP) framework to preprocess and analyze tweets. Their methodology involves using the Bag of Words (BoW) and Term Frequency-Inverse Document Frequency (TF-IDF) models to classify tweets as positive or negative. They highlight the advantages of combining BoW and TF-IDF to enhance the accuracy of sentiment analysis. Using Twitter's streaming API, they collected and processed tweets, applying techniques such as tokenization, stemming, and lemmatization. Their classifier, based on logistic regression, achieved an accuracy of 85.25%. This approach demonstrates the potential of using social media data for real-time sentiment analysis, offering valuable insights for improving product marketing strategies and customer satisfaction. The paper details the architectural design, algorithms used, and the significant improvement in sentiment analysis accuracy through their proposed system.
  - Summary Paper 2: [@10093674]
    - The paper "Sentiment Analysis on E-commerce Reviews and Ratings using ML & NLP Models to Understand Consumer Behavior" by Priyanshi Kathuria, Parth Sethi, and Rithwick Negi, investigates how machine learning (ML) and natural language processing (NLP) can be applied to e-commerce reviews and ratings to gain insights into consumer behavior. Using the Women’s E-commerce Clothing Reviews dataset, which contains 23,485 reviews from various e-commerce platforms, the authors employed ML models such as logistic regression, AdaBoost, SVM, Naive Bayes, and random forest, alongside NLP tools like Vader and TextBlob, to analyze and classify reviews. They focused on aspects such as ratings, review text, and recommendations to establish a relationship between these factors and consumer purchasing decisions. The research highlights the importance of sentiment analysis in understanding electronic word-of-mouth (eWOM) and its impact on customer attitudes and product sales. By cleaning and preprocessing the data, removing special characters and stopwords, and using exploratory data analysis (EDA), they developed a robust model to predict consumer sentiment, ultimately providing valuable insights for e-commerce businesses to enhance their marketing strategies and improve customer satisfaction.
  - Summary Paper 3: [@nasukawa2003sentiment]
    - The paper "Sentiment Analysis: Capturing Favorability Using Natural Language Processing" by Tetsuya Nasukawa and Jeonghee Yi presents a sentiment analysis methodology focused on extracting sentiments associated with specific subjects rather than classifying entire documents. This approach is essential for applications such as competitive analysis, marketing analysis, and risk management. The authors emphasize the complexity of identifying sentiments and their polarity (positive or negative) within texts, which requires an understanding of semantic relationships between sentiment expressions and subjects. Their prototype system employs a syntactic parser and a sentiment lexicon to achieve high precision (75-95%) in detecting sentiments in web pages and news articles. The paper discusses the construction of the sentiment lexicon, which includes various parts of speech such as adjectives, nouns, adverbs, and verbs, each annotated with polarity and contextual usage. By focusing on local sentiment expressions, the system provides detailed insights into specific opinions rather than general document-level sentiment. This granularity allows for more precise sentiment analysis, offering valuable information for businesses to monitor public opinion and address unfavorable sentiments effectively. The authors also highlight the limitations of previous sentiment analysis methods, which often overlook the nuanced relationships between sentiment expressions and subjects, leading to less accurate results.
  - Summary Paper 4: [@9428793]
    - The paper "Detecting Advance Fee Fraud Using NLP Bag of Word Model" by B.K. Jha and S.C. Gupta explores the application of natural language processing (NLP) techniques to identify advance fee fraud in email communications. This type of fraud, often referred to as 419 scams, typically involves scammers requesting advance payments for goods, services, or financial gains that are never delivered. The authors utilized a Bag of Words (BoW) model, a common NLP technique that represents text data as a collection of words and their frequencies, to analyze the content of emails. In their research, Jha and Gupta collected a dataset of genuine and fraudulent emails, which was then preprocessed to remove special characters, stopwords, and perform tokenization. The cleaned data was transformed into a BoW representation, which served as the input for various machine learning algorithms. The authors experimented with multiple classifiers, including logistic regression, support vector machines (SVM), Naive Bayes, and random forest, to determine the most effective model for detecting fraudulent emails. The study highlights the importance of feature extraction and selection in enhancing the performance of the classifiers. By analyzing word frequencies and patterns commonly found in fraudulent emails, the researchers were able to develop a model that successfully distinguishes between legitimate and scam communications. Their findings demonstrate the potential of NLP and machine learning techniques in automating the detection of advance fee fraud, thereby contributing to improved cybersecurity measures and protecting users from financial scams.
  - Summary Paper 5: [@7219856]
    - The paper “NLP Based Sentiment Analysis on Twitter Data Using Ensemble Classifiers” by Monisha Kanakaraj and Ram Mohana Reddy Guddeti from the Dept. of Information Technology, National Institute of Technology Karnataka, discusses an enhanced sentiment classification approach using Natural Language Processing (NLP) techniques and ensemble classifiers. Traditional sentiment analysis systems often utilize the bag-of-words model, which can lead to misleading results due to the lack of contextual understanding. This paper proposes incorporating semantic information into feature vectors and employing ensemble classifiers to improve sentiment classification accuracy. By adding semantically similar words and context-sense identities, the proposed method achieves a 3-5% increase in prediction accuracy compared to traditional methods. The research involves analyzing Twitter data to determine public sentiment on various topics and demonstrates that the ensemble classifier approach, which combines multiple machine learning algorithms, outperforms solitary methods in terms of precision, recall, and F-score. The results indicate that extremely randomized trees, a type of ensemble method, provide the best performance due to their high randomness in computing splits. The study concludes that integrating semantics with ensemble classification systems significantly enhances sentiment analysis on social media data.